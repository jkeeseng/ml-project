{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5279.69s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.24.3 in ./Library/Python/3.9/lib/python/site-packages (1.24.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.24.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to your audio directories\n",
    "koala_dir = '/Users/joanne/Desktop/koala_classification_project/koala/'\n",
    "non_koala_dir = '/Users/joanne/Desktop/koala_classification_project/non_koala/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_koala_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5522.86s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./Library/Python/3.9/lib/python/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in ./Library/Python/3.9/lib/python/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in ./Library/Python/3.9/lib/python/site-packages (2.3.1)\n",
      "Requirement already satisfied: librosa in ./Library/Python/3.9/lib/python/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: numpy in ./Library/Python/3.9/lib/python/site-packages (1.24.3)\n",
      "Requirement already satisfied: jinja2 in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: networkx in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: sympy in ./Library/Python/3.9/lib/python/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in ./Library/Python/3.9/lib/python/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./Library/Python/3.9/lib/python/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: pooch>=1.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: joblib>=0.14 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: packaging in ./Library/Python/3.9/lib/python/site-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./Library/Python/3.9/lib/python/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./Library/Python/3.9/lib/python/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./Library/Python/3.9/lib/python/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./Library/Python/3.9/lib/python/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./Library/Python/3.9/lib/python/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./Library/Python/3.9/lib/python/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio librosa numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./Library/Python/3.9/lib/python/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in ./Library/Python/3.9/lib/python/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in ./Library/Python/3.9/lib/python/site-packages (2.3.1)\n",
      "Requirement already satisfied: librosa in ./Library/Python/3.9/lib/python/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: numpy in ./Library/Python/3.9/lib/python/site-packages (1.24.3)\n",
      "Requirement already satisfied: jinja2 in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./Library/Python/3.9/lib/python/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: networkx in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./Library/Python/3.9/lib/python/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: filelock in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./Library/Python/3.9/lib/python/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: joblib>=0.14 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: packaging in ./Library/Python/3.9/lib/python/site-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./Library/Python/3.9/lib/python/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./Library/Python/3.9/lib/python/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./Library/Python/3.9/lib/python/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.7.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./Library/Python/3.9/lib/python/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./Library/Python/3.9/lib/python/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./Library/Python/3.9/lib/python/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio librosa numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def list_audio_files(directory):\n",
    "    return [os.path.join(directory, filename) for filename in os.listdir(directory) if filename.endswith('.wav')]\n",
    "\n",
    "def load_audio_files(file_paths, sr=22050):\n",
    "    return [librosa.load(file_path, sr=sr)[0] for file_path in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(audio, sr=22050):\n",
    "    # Example augmentations: add your own methods as needed\n",
    "    augmented_audios = []\n",
    "    \n",
    "    # Time stretching\n",
    "    augmented_audios.append(librosa.effects.time_stretch(audio, rate=0.9))\n",
    "    augmented_audios.append(librosa.effects.time_stretch(audio, rate=1.1))\n",
    "    \n",
    "    # Pitch shifting\n",
    "    augmented_audios.append(librosa.effects.pitch_shift(audio, sr=sr, n_steps=-2))\n",
    "    augmented_audios.append(librosa.effects.pitch_shift(audio, sr=sr, n_steps=2))\n",
    "    \n",
    "    return augmented_audios\n",
    "\n",
    "def pad_or_truncate(audio, target_length):\n",
    "    if len(audio) < target_length:\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
    "    elif len(audio) > target_length:\n",
    "        audio = audio[:target_length]\n",
    "    return audio\n",
    "\n",
    "def prepare_data(directory, target_length=16000, num_augmentations_per_sample=2):\n",
    "    file_paths = list_audio_files(directory)\n",
    "    data = load_audio_files(file_paths, sr=22050)\n",
    "    \n",
    "    augmented_data = []\n",
    "    for audio in data:\n",
    "        augmented_audios = augment_audio(audio, sr=22050)\n",
    "        augmented_data.extend([pad_or_truncate(a, target_length) for a in augmented_audios[:num_augmentations_per_sample]])\n",
    "    \n",
    "    # Pad or truncate original data\n",
    "    data = [pad_or_truncate(audio, target_length) for audio in data]\n",
    "\n",
    "    return data + augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of koala samples: 540\n",
      "Number of non-koala samples: 560\n",
      "Batch shape: torch.Size([32, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "def audio_to_melspectrogram(audio, sr=22050, n_mels=128, max_len=128):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    if mel_spec_db.shape[1] < max_len:\n",
    "        pad_width = max_len - mel_spec_db.shape[1]\n",
    "        mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mel_spec_db = mel_spec_db[:, :max_len]\n",
    "    return mel_spec_db\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, max_len=128):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        mel_spec_db = audio_to_melspectrogram(audio, max_len=self.max_len)\n",
    "        \n",
    "        # Add channel dimension: [n_mels, max_len] -> [1, n_mels, max_len]\n",
    "        mel_spec_db = np.expand_dims(mel_spec_db, axis=0)  # Shape: [1, n_mels, max_len]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        mel_spec_db = torch.tensor(mel_spec_db, dtype=torch.float32)\n",
    "        \n",
    "        return mel_spec_db, label\n",
    "\n",
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts numpy array to torch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize\n",
    "])\n",
    "\n",
    "# Example function to prepare data\n",
    "def prepare_data(data_dir, target_length=16000, augment_audio_func=None, num_augmentations_per_sample=0):\n",
    "    data = []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            audio, _ = librosa.load(file_path, sr=22050)\n",
    "            if len(audio) > target_length:\n",
    "                audio = audio[:target_length]\n",
    "            elif len(audio) < target_length:\n",
    "                audio = np.pad(audio, (0, target_length - len(audio)), 'constant')\n",
    "\n",
    "            data.append(audio)\n",
    "\n",
    "            if augment_audio_func:\n",
    "                for _ in range(num_augmentations_per_sample):\n",
    "                    augmented_audio = augment_audio_func(audio)\n",
    "                    data.append(augmented_audio)\n",
    "\n",
    "    return np.array(data)\n",
    "\n",
    "# Example augment function\n",
    "def augment_audio(audio):\n",
    "    return audio[::-1]  # Example: reverse the audio as a simple augmentation\n",
    "\n",
    "# Load your data\n",
    "koala_dir = \"/Users/joanne/Desktop/koala_classification_project/koala/\"\n",
    "non_koala_dir = \"/Users/joanne/Desktop/koala_classification_project/non_koala/\"\n",
    "koala_data = prepare_data(koala_dir, target_length=16000, augment_audio_func=augment_audio, num_augmentations_per_sample=2)\n",
    "non_koala_data = prepare_data(non_koala_dir, target_length=16000)\n",
    "\n",
    "# Check the data lengths\n",
    "print(f'Number of koala samples: {len(koala_data)}')\n",
    "print(f'Number of non-koala samples: {len(non_koala_data)}')\n",
    "\n",
    "# Ensure you have 540 koala samples and 560 non-koala samples\n",
    "assert len(koala_data) == 540, \"Koala data does not have 540 samples\"\n",
    "assert len(non_koala_data) == 560, \"Non-koala data does not have 560 samples\"\n",
    "\n",
    "koala_labels = [1] * len(koala_data)\n",
    "non_koala_labels = [0] * len(non_koala_data)\n",
    "\n",
    "# Combine the datasets\n",
    "data = np.concatenate((koala_data, non_koala_data), axis=0)\n",
    "labels = np.array(koala_labels + non_koala_labels)\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = AudioDataset(data, labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Check the batch shape\n",
    "for inputs, labels in train_loader:\n",
    "    print(\"Batch shape:\", inputs.shape)  # Should be [batch_size, channels, height, width]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of koala samples: 540\n",
      "Number of non-koala samples: 560\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import librosa\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "def audio_to_melspectrogram(audio, sr=22050, n_mels=128, max_len=128):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    if mel_spec_db.shape[1] < max_len:\n",
    "        pad_width = max_len - mel_spec_db.shape[1]\n",
    "        mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mel_spec_db = mel_spec_db[:, :max_len]\n",
    "    return mel_spec_db\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, max_len=128):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        mel_spec_db = audio_to_melspectrogram(audio, max_len=self.max_len)\n",
    "        \n",
    "        # Add channel dimension: [n_mels, max_len] -> [1, n_mels, max_len]\n",
    "        mel_spec_db = np.expand_dims(mel_spec_db, axis=0)  # Shape: [1, n_mels, max_len]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        mel_spec_db = torch.tensor(mel_spec_db, dtype=torch.float32)\n",
    "        \n",
    "        return mel_spec_db, label\n",
    "\n",
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts numpy array to torch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize\n",
    "])\n",
    "\n",
    "# Example function to prepare data\n",
    "def prepare_data(data_dir, target_length=16000, augment_audio_func=None, num_augmentations_per_sample=0):\n",
    "    data = []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            audio, _ = librosa.load(file_path, sr=22050)\n",
    "            if len(audio) > target_length:\n",
    "                audio = audio[:target_length]\n",
    "            elif len(audio) < target_length:\n",
    "                audio = np.pad(audio, (0, target_length - len(audio)), 'constant')\n",
    "\n",
    "            data.append(audio)\n",
    "\n",
    "            if augment_audio_func:\n",
    "                for _ in range(num_augmentations_per_sample):\n",
    "                    augmented_audio = augment_audio_func(audio)\n",
    "                    data.append(augmented_audio)\n",
    "\n",
    "    return np.array(data)\n",
    "\n",
    "# Example augment function\n",
    "def augment_audio(audio):\n",
    "    return audio[::-1]  # Example: reverse the audio as a simple augmentation\n",
    "\n",
    "# Load your data\n",
    "koala_dir = \"/Users/joanne/Desktop/koala_classification_project/koala/\"\n",
    "non_koala_dir = \"/Users/joanne/Desktop/koala_classification_project/non_koala/\"\n",
    "koala_data = prepare_data(koala_dir, target_length=16000, augment_audio_func=augment_audio, num_augmentations_per_sample=2)\n",
    "non_koala_data = prepare_data(non_koala_dir, target_length=16000)\n",
    "\n",
    "# Check the data lengths\n",
    "print(f'Number of koala samples: {len(koala_data)}')\n",
    "print(f'Number of non-koala samples: {len(non_koala_data)}')\n",
    "\n",
    "# Ensure you have 540 koala samples and 560 non-koala samples\n",
    "assert len(koala_data) == 540, \"Koala data does not have 540 samples\"\n",
    "assert len(non_koala_data) == 560, \"Non-koala data does not have 560 samples\"\n",
    "\n",
    "koala_labels = [1] * len(koala_data)\n",
    "non_koala_labels = [0] * len(non_koala_data)\n",
    "\n",
    "# Combine the datasets\n",
    "data = np.concatenate((koala_data, non_koala_data), axis=0)\n",
    "labels = np.array(koala_labels + non_koala_labels)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = AudioDataset(data, labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNetAudioClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNetAudioClassifier, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(in_features=self.resnet.fc.in_features, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.3562, Val Loss: 2.9488, Val Accuracy: 50.91%\n",
      "Epoch 2/10, Train Loss: 0.1852, Val Loss: 0.5636, Val Accuracy: 68.18%\n",
      "Epoch 3/10, Train Loss: 0.1714, Val Loss: 0.8391, Val Accuracy: 81.82%\n",
      "Epoch 4/10, Train Loss: 0.1645, Val Loss: 0.2544, Val Accuracy: 90.00%\n",
      "Epoch 5/10, Train Loss: 0.1707, Val Loss: 0.2153, Val Accuracy: 89.09%\n",
      "Epoch 6/10, Train Loss: 0.1379, Val Loss: 3.2615, Val Accuracy: 47.27%\n",
      "Epoch 7/10, Train Loss: 0.1852, Val Loss: 0.5290, Val Accuracy: 77.27%\n",
      "Epoch 8/10, Train Loss: 0.1267, Val Loss: 0.9463, Val Accuracy: 77.27%\n",
      "Epoch 9/10, Train Loss: 0.1409, Val Loss: 0.6863, Val Accuracy: 66.36%\n",
      "Epoch 10/10, Train Loss: 0.1239, Val Loss: 2.5030, Val Accuracy: 48.18%\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.3981, Val Loss: 0.6324, Val Accuracy: 83.64%\n",
      "Epoch 2/10, Train Loss: 0.2002, Val Loss: 0.8059, Val Accuracy: 70.00%\n",
      "Epoch 3/10, Train Loss: 0.2106, Val Loss: 0.2704, Val Accuracy: 90.00%\n",
      "Epoch 4/10, Train Loss: 0.1384, Val Loss: 0.1950, Val Accuracy: 92.73%\n",
      "Epoch 5/10, Train Loss: 0.1294, Val Loss: 0.3179, Val Accuracy: 90.00%\n",
      "Epoch 6/10, Train Loss: 0.1187, Val Loss: 0.2934, Val Accuracy: 90.91%\n",
      "Epoch 7/10, Train Loss: 0.1324, Val Loss: 0.1436, Val Accuracy: 92.73%\n",
      "Epoch 8/10, Train Loss: 0.1054, Val Loss: 0.3199, Val Accuracy: 87.27%\n",
      "Epoch 9/10, Train Loss: 0.0753, Val Loss: 0.2356, Val Accuracy: 92.73%\n",
      "Epoch 10/10, Train Loss: 0.0888, Val Loss: 0.1895, Val Accuracy: 93.64%\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.3799, Val Loss: 4.0994, Val Accuracy: 50.91%\n",
      "Epoch 2/10, Train Loss: 0.2132, Val Loss: 0.2244, Val Accuracy: 87.27%\n",
      "Epoch 3/10, Train Loss: 0.1904, Val Loss: 0.1558, Val Accuracy: 94.55%\n",
      "Epoch 4/10, Train Loss: 0.1580, Val Loss: 0.1321, Val Accuracy: 93.64%\n",
      "Epoch 5/10, Train Loss: 0.1375, Val Loss: 0.4815, Val Accuracy: 83.64%\n",
      "Epoch 6/10, Train Loss: 0.1130, Val Loss: 0.7312, Val Accuracy: 69.09%\n",
      "Epoch 7/10, Train Loss: 0.1184, Val Loss: 0.6967, Val Accuracy: 78.18%\n",
      "Epoch 8/10, Train Loss: 0.1141, Val Loss: 0.8839, Val Accuracy: 65.45%\n",
      "Epoch 9/10, Train Loss: 0.1183, Val Loss: 0.4355, Val Accuracy: 82.73%\n",
      "Epoch 10/10, Train Loss: 0.1262, Val Loss: 0.5758, Val Accuracy: 83.64%\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.5244, Val Loss: 0.4563, Val Accuracy: 81.82%\n",
      "Epoch 2/10, Train Loss: 0.2635, Val Loss: 0.2110, Val Accuracy: 91.82%\n",
      "Epoch 3/10, Train Loss: 0.1838, Val Loss: 0.2147, Val Accuracy: 88.18%\n",
      "Epoch 4/10, Train Loss: 0.1777, Val Loss: 0.4874, Val Accuracy: 74.55%\n",
      "Epoch 5/10, Train Loss: 0.1511, Val Loss: 1.1511, Val Accuracy: 75.45%\n",
      "Epoch 6/10, Train Loss: 0.1993, Val Loss: 0.2446, Val Accuracy: 84.55%\n",
      "Epoch 7/10, Train Loss: 0.1649, Val Loss: 0.0981, Val Accuracy: 93.64%\n",
      "Epoch 8/10, Train Loss: 0.1299, Val Loss: 0.1311, Val Accuracy: 96.36%\n",
      "Epoch 9/10, Train Loss: 0.1373, Val Loss: 0.5304, Val Accuracy: 70.91%\n",
      "Epoch 10/10, Train Loss: 0.1120, Val Loss: 0.1508, Val Accuracy: 92.73%\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.3593, Val Loss: 0.1975, Val Accuracy: 93.64%\n",
      "Epoch 2/10, Train Loss: 0.2258, Val Loss: 0.3535, Val Accuracy: 86.36%\n",
      "Epoch 3/10, Train Loss: 0.1510, Val Loss: 2.3875, Val Accuracy: 58.18%\n",
      "Epoch 4/10, Train Loss: 0.1841, Val Loss: 1.5626, Val Accuracy: 61.82%\n",
      "Epoch 5/10, Train Loss: 0.1515, Val Loss: 0.1557, Val Accuracy: 91.82%\n",
      "Epoch 6/10, Train Loss: 0.1060, Val Loss: 0.5671, Val Accuracy: 86.36%\n",
      "Epoch 7/10, Train Loss: 0.1340, Val Loss: 0.1604, Val Accuracy: 91.82%\n",
      "Epoch 8/10, Train Loss: 0.0900, Val Loss: 0.1284, Val Accuracy: 95.45%\n",
      "Epoch 9/10, Train Loss: 0.1378, Val Loss: 0.5729, Val Accuracy: 86.36%\n",
      "Epoch 10/10, Train Loss: 0.0660, Val Loss: 0.2270, Val Accuracy: 93.64%\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.4510, Val Loss: 2.4788, Val Accuracy: 42.73%\n",
      "Epoch 2/10, Train Loss: 0.2454, Val Loss: 1.3872, Val Accuracy: 43.64%\n",
      "Epoch 3/10, Train Loss: 0.2132, Val Loss: 0.5712, Val Accuracy: 82.73%\n",
      "Epoch 4/10, Train Loss: 0.1887, Val Loss: 0.1808, Val Accuracy: 93.64%\n",
      "Epoch 5/10, Train Loss: 0.1723, Val Loss: 0.0737, Val Accuracy: 96.36%\n",
      "Epoch 6/10, Train Loss: 0.1430, Val Loss: 0.0913, Val Accuracy: 95.45%\n",
      "Epoch 7/10, Train Loss: 0.1623, Val Loss: 0.0829, Val Accuracy: 97.27%\n",
      "Epoch 8/10, Train Loss: 0.1329, Val Loss: 0.0880, Val Accuracy: 97.27%\n",
      "Epoch 9/10, Train Loss: 0.1112, Val Loss: 0.1048, Val Accuracy: 95.45%\n",
      "Epoch 10/10, Train Loss: 0.1049, Val Loss: 0.0679, Val Accuracy: 97.27%\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.3859, Val Loss: 0.3250, Val Accuracy: 90.91%\n",
      "Epoch 2/10, Train Loss: 0.2090, Val Loss: 0.5013, Val Accuracy: 84.55%\n",
      "Epoch 3/10, Train Loss: 0.2149, Val Loss: 0.2592, Val Accuracy: 90.91%\n",
      "Epoch 4/10, Train Loss: 0.2100, Val Loss: 1.3923, Val Accuracy: 53.64%\n",
      "Epoch 5/10, Train Loss: 0.1403, Val Loss: 0.2323, Val Accuracy: 93.64%\n",
      "Epoch 6/10, Train Loss: 0.1043, Val Loss: 0.7917, Val Accuracy: 70.91%\n",
      "Epoch 7/10, Train Loss: 0.0584, Val Loss: 3.5831, Val Accuracy: 51.82%\n",
      "Epoch 8/10, Train Loss: 0.1143, Val Loss: 0.6397, Val Accuracy: 81.82%\n",
      "Epoch 9/10, Train Loss: 0.1182, Val Loss: 1.9758, Val Accuracy: 51.82%\n",
      "Epoch 10/10, Train Loss: 0.1067, Val Loss: 0.3205, Val Accuracy: 90.91%\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.3860, Val Loss: 0.4732, Val Accuracy: 82.73%\n",
      "Epoch 2/10, Train Loss: 0.2443, Val Loss: 0.3661, Val Accuracy: 86.36%\n",
      "Epoch 3/10, Train Loss: 0.1900, Val Loss: 0.4515, Val Accuracy: 80.00%\n",
      "Epoch 4/10, Train Loss: 0.1893, Val Loss: 0.2613, Val Accuracy: 88.18%\n",
      "Epoch 5/10, Train Loss: 0.1554, Val Loss: 0.4424, Val Accuracy: 84.55%\n",
      "Epoch 6/10, Train Loss: 0.1275, Val Loss: 0.7903, Val Accuracy: 77.27%\n",
      "Epoch 7/10, Train Loss: 0.1266, Val Loss: 1.0876, Val Accuracy: 81.82%\n",
      "Epoch 8/10, Train Loss: 0.1430, Val Loss: 0.3269, Val Accuracy: 88.18%\n",
      "Epoch 9/10, Train Loss: 0.1265, Val Loss: 1.0931, Val Accuracy: 55.45%\n",
      "Epoch 10/10, Train Loss: 0.1067, Val Loss: 0.1190, Val Accuracy: 94.55%\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.4439, Val Loss: 0.6669, Val Accuracy: 70.00%\n",
      "Epoch 2/10, Train Loss: 0.2050, Val Loss: 0.2052, Val Accuracy: 92.73%\n",
      "Epoch 3/10, Train Loss: 0.1777, Val Loss: 0.1870, Val Accuracy: 90.91%\n",
      "Epoch 4/10, Train Loss: 0.1399, Val Loss: 0.5972, Val Accuracy: 68.18%\n",
      "Epoch 5/10, Train Loss: 0.1740, Val Loss: 0.4896, Val Accuracy: 87.27%\n",
      "Epoch 6/10, Train Loss: 0.1269, Val Loss: 0.1350, Val Accuracy: 95.45%\n",
      "Epoch 7/10, Train Loss: 0.1147, Val Loss: 0.3168, Val Accuracy: 88.18%\n",
      "Epoch 8/10, Train Loss: 0.0879, Val Loss: 0.2108, Val Accuracy: 92.73%\n",
      "Epoch 9/10, Train Loss: 0.0777, Val Loss: 0.3454, Val Accuracy: 89.09%\n",
      "Epoch 10/10, Train Loss: 0.0732, Val Loss: 0.2929, Val Accuracy: 87.27%\n",
      "FOLD 10\n",
      "--------------------------------\n",
      "Epoch 1/10, Train Loss: 0.4841, Val Loss: 1.8288, Val Accuracy: 60.91%\n",
      "Epoch 2/10, Train Loss: 0.2408, Val Loss: 1.2121, Val Accuracy: 50.91%\n",
      "Epoch 3/10, Train Loss: 0.2141, Val Loss: 0.2385, Val Accuracy: 88.18%\n",
      "Epoch 4/10, Train Loss: 0.1829, Val Loss: 1.7243, Val Accuracy: 45.45%\n",
      "Epoch 5/10, Train Loss: 0.1649, Val Loss: 0.1072, Val Accuracy: 95.45%\n",
      "Epoch 6/10, Train Loss: 0.1391, Val Loss: 0.1241, Val Accuracy: 94.55%\n",
      "Epoch 7/10, Train Loss: 0.1091, Val Loss: 0.1036, Val Accuracy: 95.45%\n",
      "Epoch 8/10, Train Loss: 0.1092, Val Loss: 1.5004, Val Accuracy: 54.55%\n",
      "Epoch 9/10, Train Loss: 0.1111, Val Loss: 0.1405, Val Accuracy: 94.55%\n",
      "Epoch 10/10, Train Loss: 0.1021, Val Loss: 2.5878, Val Accuracy: 45.45%\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS\n",
      "--------------------------------\n",
      "Fold 1: 48.18%\n",
      "Fold 2: 93.64%\n",
      "Fold 3: 83.64%\n",
      "Fold 4: 92.73%\n",
      "Fold 5: 93.64%\n",
      "Fold 6: 97.27%\n",
      "Fold 7: 90.91%\n",
      "Fold 8: 94.55%\n",
      "Fold 9: 87.27%\n",
      "Fold 10: 45.45%\n",
      "Average Accuracy: 82.73%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Updated ResNetAudioClassifier with weights argument\n",
    "class ResNetAudioClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNetAudioClassifier, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(in_features=self.resnet.fc.in_features, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Assume you have the AudioDataset class and data preparation functions defined as before\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return running_loss / len(val_loader), accuracy\n",
    "\n",
    "def cross_validate_model(dataset, k_folds=10, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        print(f'FOLD {fold+1}')\n",
    "        print('--------------------------------')\n",
    "        \n",
    "        train_subsampler = Subset(dataset, train_ids)\n",
    "        val_subsampler = Subset(dataset, val_ids)\n",
    "        \n",
    "        train_loader = DataLoader(train_subsampler, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subsampler, batch_size=32, shuffle=False)\n",
    "        \n",
    "        model = ResNetAudioClassifier(num_classes=2).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_accuracy = validate_model(model, val_loader, criterion, device)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        results[fold] = val_accuracy\n",
    "    \n",
    "    print('--------------------------------')\n",
    "    print('K-FOLD CROSS VALIDATION RESULTS')\n",
    "    print('--------------------------------')\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key+1}: {value:.2f}%')\n",
    "    avg_accuracy = np.mean(list(results.values()))\n",
    "    print(f'Average Accuracy: {avg_accuracy:.2f}%')\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_validate_model(train_dataset, k_folds=10, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./Library/Python/3.9/lib/python/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in ./Library/Python/3.9/lib/python/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in ./Library/Python/3.9/lib/python/site-packages (2.3.1)\n",
      "Requirement already satisfied: librosa in ./Library/Python/3.9/lib/python/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: jinja2 in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./Library/Python/3.9/lib/python/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: networkx in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: filelock in ./Library/Python/3.9/lib/python/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: sympy in ./Library/Python/3.9/lib/python/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./Library/Python/3.9/lib/python/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: numpy in ./Library/Python/3.9/lib/python/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: joblib>=0.14 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./Library/Python/3.9/lib/python/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: packaging in ./Library/Python/3.9/lib/python/site-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./Library/Python/3.9/lib/python/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./Library/Python/3.9/lib/python/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./Library/Python/3.9/lib/python/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./Library/Python/3.9/lib/python/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./Library/Python/3.9/lib/python/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./Library/Python/3.9/lib/python/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.1-cp39-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 61.0 MB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp39-cp39-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.3.1-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in ./Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.13.0-py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./Library/Python/3.9/lib/python/site-packages (from torchvision) (1.24.3)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_universal2.whl (18 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: mpmath, MarkupSafe, sympy, networkx, jinja2, fsspec, filelock, torch, pillow, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.15.4 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.2.1 pillow-10.4.0 sympy-1.13.0 torch-2.3.1 torchaudio-2.3.1 torchvision-0.18.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
